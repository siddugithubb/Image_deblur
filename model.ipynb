{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d6fee3-bbfb-4861-a4ab-12fba6686f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebcec4c6-eb13-4cda-a087-510467d85f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently allocated GPU memory: 0.0 MB\n",
      "Peak GPU memory usage: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = torch.cuda.memory_allocated()\n",
    "print(\"Currently allocated GPU memory:\", allocated_memory / 1024**2, \"MB\")\n",
    "\n",
    "# Get peak memory usage\n",
    "peak_memory = torch.cuda.max_memory_allocated()\n",
    "print(\"Peak GPU memory usage:\", peak_memory / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3be407-d35b-44f6-99f1-a88d9c5b0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 1 Total Memory: 6140.5 MB\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Get information about each GPU\n",
    "for i in range(num_gpus):\n",
    "    properties = torch.cuda.get_device_properties(i)\n",
    "    print(\"GPU\", i+1, \"Total Memory:\", properties.total_memory / (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5221f4da-bf5d-4df9-a113-4590b7c01456",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efbbdfed-ba09-480c-849f-3307a06d206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324c6503-fe6a-419b-b14a-abd8e9c022a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_image_path = self.dataframe.iloc[idx, 0]\n",
    "        final_image_path = self.dataframe.iloc[idx, 1]\n",
    "        input_image = Image.open(input_image_path)\n",
    "        final_image = Image.open(final_image_path)\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            final_image = self.transform(final_image)\n",
    "        return input_image, final_image\n",
    "\n",
    "# Data Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "dataframe = pd.read_csv(\"paths.csv\")\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "# dataset = CustomDataset(dataframe, transform=transform)\n",
    "\n",
    "# # DataLoader\n",
    "# batch_size = 8\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36298cd8-8d79-44f8-ac75-4a6c4f76916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 448]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 448]             128\n",
      "              ReLU-3         [-1, 64, 256, 448]               0\n",
      "            Conv2d-4         [-1, 64, 256, 448]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 448]             128\n",
      "              ReLU-6         [-1, 64, 256, 448]               0\n",
      "            Conv2d-7        [-1, 128, 256, 448]          73,856\n",
      "       BatchNorm2d-8        [-1, 128, 256, 448]             256\n",
      "              ReLU-9        [-1, 128, 256, 448]               0\n",
      "           Conv2d-10        [-1, 128, 256, 448]         147,584\n",
      "      BatchNorm2d-11        [-1, 128, 256, 448]             256\n",
      "             ReLU-12        [-1, 128, 256, 448]               0\n",
      "           Conv2d-13        [-1, 256, 256, 448]         295,168\n",
      "      BatchNorm2d-14        [-1, 256, 256, 448]             512\n",
      "             ReLU-15        [-1, 256, 256, 448]               0\n",
      "           Conv2d-16        [-1, 256, 256, 448]         590,080\n",
      "      BatchNorm2d-17        [-1, 256, 256, 448]             512\n",
      "             ReLU-18        [-1, 256, 256, 448]               0\n",
      "           Conv2d-19        [-1, 256, 256, 448]       1,638,656\n",
      "      BatchNorm2d-20        [-1, 256, 256, 448]             512\n",
      "             ReLU-21        [-1, 256, 256, 448]               0\n",
      "           Conv2d-22        [-1, 256, 256, 448]         590,080\n",
      "      BatchNorm2d-23        [-1, 256, 256, 448]             512\n",
      "             ReLU-24        [-1, 256, 256, 448]               0\n",
      "  ConvTranspose2d-25        [-1, 256, 256, 448]       1,638,656\n",
      "      BatchNorm2d-26        [-1, 256, 256, 448]             512\n",
      "             ReLU-27        [-1, 256, 256, 448]               0\n",
      "           Conv2d-28        [-1, 256, 256, 448]         590,080\n",
      "      BatchNorm2d-29        [-1, 256, 256, 448]             512\n",
      "             ReLU-30        [-1, 256, 256, 448]               0\n",
      "  ConvTranspose2d-31        [-1, 128, 256, 448]         295,040\n",
      "      BatchNorm2d-32        [-1, 128, 256, 448]             256\n",
      "             ReLU-33        [-1, 128, 256, 448]               0\n",
      "           Conv2d-34        [-1, 128, 256, 448]         147,584\n",
      "      BatchNorm2d-35        [-1, 128, 256, 448]             256\n",
      "             ReLU-36        [-1, 128, 256, 448]               0\n",
      "  ConvTranspose2d-37         [-1, 64, 256, 448]          73,792\n",
      "      BatchNorm2d-38         [-1, 64, 256, 448]             128\n",
      "             ReLU-39         [-1, 64, 256, 448]               0\n",
      "           Conv2d-40         [-1, 64, 256, 448]          36,928\n",
      "      BatchNorm2d-41         [-1, 64, 256, 448]             128\n",
      "             ReLU-42         [-1, 64, 256, 448]               0\n",
      "  ConvTranspose2d-43          [-1, 3, 256, 448]           1,731\n",
      "             Tanh-44          [-1, 3, 256, 448]               0\n",
      "================================================================\n",
      "Total params: 6,162,563\n",
      "Trainable params: 6,162,563\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.31\n",
      "Forward/backward pass size (MB): 6053.25\n",
      "Params size (MB): 23.51\n",
      "Estimated Total Size (MB): 6078.07\n",
      "----------------------------------------------------------------\n",
      "Output tensor shape: torch.Size([1, 3, 256, 448])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeblurModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeblurModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeblurModel().to(device)\n",
    "summary(model, (3, 256, 448))  # Print summary of the model\n",
    "input_tensor = torch.randn(1, 3, 256, 448).to(device)\n",
    "\n",
    "  \n",
    "output_tensor = model(input_tensor)\n",
    "print(\"Output tensor shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d0cb33-fd54-4cbf-9f9a-0b065de8cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently allocated GPU memory: 2045.68310546875 MB\n",
      "Peak GPU memory usage: 6574.123046875 MB\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = torch.cuda.memory_allocated()\n",
    "print(\"Currently allocated GPU memory:\", allocated_memory / 1024**2, \"MB\")\n",
    "\n",
    "# Get peak memory usage\n",
    "peak_memory = torch.cuda.max_memory_allocated()\n",
    "print(\"Peak GPU memory usage:\", peak_memory / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b87db89b-ea78-44b4-ae5f-535f32800c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict = torch.load('trained_model_sid.pth')\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9f8186-a184-41a9-ac74-47092c72bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe=dataframe.iloc[:2000]\n",
    "\n",
    "from torch.utils.data import Subset, random_split\n",
    "\n",
    "dataset = CustomDataset(dataframe, transform=transform) \n",
    "# train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create train and validation loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c24720-0bd0-4684-8038-222ee3ef8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc104b-481a-447a-94bf-0333bf039f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for i, (input_images, final_images) in enumerate(train_loader):\n",
    "        input_images = input_images.to(device)\n",
    "        final_images = final_images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(input_images)\n",
    "            train_loss = criterion(outputs, final_images)\n",
    "        scaler.scale(train_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_train_loss += train_loss.item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, len(train_loader), train_loss.item()))\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input_images, final_images) in enumerate(val_loader):\n",
    "            input_images = input_images.to(device)\n",
    "            final_images = final_images.to(device)\n",
    "\n",
    "            outputs = model(input_images)\n",
    "            val_loss = criterion(outputs, final_images)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch + 1, num_epochs, avg_train_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67bd28fa-070e-4576-acc2-6ec9ba2b2913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'trained_model_sid_2.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47761a2a-f911-42cf-b7d7-39bb0ee903cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25990e-0dcf-4b04-a28d-64015b22d4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
